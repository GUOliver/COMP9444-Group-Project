{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "wAnEGxI0kRYI"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------#\n",
        "# Title:        Group Project - Music Genre Classification                     #\n",
        "# Course:       COMP9444 Neural Networks 2022 Term Three                       #\n",
        "# Mentor:       Arun Kumar Marndi                                              #\n",
        "# Session:      Thursday 16:00 - 18:00                                         #\n",
        "#                                                                              #\n",
        "# Team:         NNKing                                                         #\n",
        "# Author/s:     Peter Huang (z5313504)                                         #\n",
        "#               Fiona Oâ€™Chee (z5122503)                                        #\n",
        "#               Evan Karl Lam (z5333206)                                       #\n",
        "#               Theo Graftieaux (z5258743)                                     #\n",
        "#               Oliver Guo (z5191682)                                          #\n",
        "#                                                                              #\n",
        "#------------------------------------------------------------------------------#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S63GD9I9jif5"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eSRrW8JoVFI"
      },
      "source": [
        "### Usage Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsUY3WDLmfAD"
      },
      "source": [
        "No execution required; all results are already displayed for convenience. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqfc8mO3jtZB"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkyU2zioDiSl",
        "outputId": "7a660318-8356-440d-9a4c-a1040db33bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/COMP9444/COMP9444-Group-Project'\n",
            "/content/drive/.shortcut-targets-by-id/1f2FfExUGYN2E54Q1zrEAFNotNfq9wlni/COMP9444/COMP9444-Group-Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/COMP9444/COMP9444-Group-Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ0UT0FawB1i",
        "outputId": "3a7e3ee8-14f5-4fd9-bc64-d3423153db80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input  main.ipynb  output\n"
          ]
        }
      ],
      "source": [
        "!ls # Confirm in project root directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "HUN3NJCBDl3m"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import warnings\n",
        "import IPython.display as ipd\n",
        "import tqdm.notebook\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "import glob\n",
        "import h5py\n",
        "import keras\n",
        "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
        "import sklearn as skl\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "kxOlN-QA1aPJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "b90WPPjRX_Ha"
      },
      "outputs": [],
      "source": [
        "INPUT_DIR = 'input'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Cgi9BJ6BrVwF"
      },
      "outputs": [],
      "source": [
        "# Helper function. Conveniently load raw data into dataframes.\n",
        "# (adapted from source: https://github.com/mdeff/fma)\n",
        "def load(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "\n",
        "    if 'features' in filename:\n",
        "        # Use rows 0, 1 and 2 to comprise feature headings\n",
        "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
        "\n",
        "    if 'echonest' in filename:\n",
        "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
        "\n",
        "    if 'tracks' in filename:\n",
        "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
        "\n",
        "        columns = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
        "                   ('track', 'genres'), ('track', 'genres_all')]\n",
        "        for c in columns:\n",
        "            tracks[c] = tracks[c].map(ast.literal_eval)\n",
        "\n",
        "        columns = [('track', 'date_created'), ('track', 'date_recorded'),\n",
        "                   ('album', 'date_created'), ('album', 'date_released'),\n",
        "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
        "                   ('artist', 'active_year_end')]\n",
        "        for c in columns:\n",
        "            tracks[c] = pd.to_datetime(tracks[c])\n",
        "\n",
        "        subsets = ('small', 'medium', 'large')\n",
        "        try:\n",
        "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "                    'category', categories=subsets, ordered=True)\n",
        "        except (ValueError, TypeError):\n",
        "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
        "                     pd.CategoricalDtype(categories=subsets, ordered=True))\n",
        "\n",
        "        columns = [('track', 'genre_top'), ('track', 'license'),\n",
        "                   ('album', 'type'), ('album', 'information'),\n",
        "                   ('artist', 'bio')]\n",
        "        for c in columns:\n",
        "            tracks[c] = tracks[c].astype('category')\n",
        "\n",
        "        return tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2L_M1gKqjeA"
      },
      "outputs": [],
      "source": [
        "# Load data from 3 FMA files which comprise the raw dataset.\n",
        "df_tracks = load(f'{INPUT_DIR}/fma_metadata/tracks.csv')\n",
        "df_features = load(f'{INPUT_DIR}/fma_metadata/features.csv')\n",
        "# df_echonest = load(f'{INPUT_DIR}/fma_metadata/echonest.csv')\n",
        "\n",
        "# Check matching dimensions\n",
        "# np.testing.assert_array_equal(df_features.index, df_tracks.index) \n",
        "# assert df_echonest.index.isin(df_tracks.index).all()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filters for selecting specific row instances \n",
        "filter_small = df_tracks.index[df_tracks['set', 'subset'] <= 'small']\n",
        "filter_train = df_tracks[('set', 'split')] == 'training'\n",
        "filter_val = df_tracks[('set', 'split')] == 'validation'\n",
        "filter_test = df_tracks[('set', 'split')] == 'test'"
      ],
      "metadata": {
        "id": "9j_kLAFk9ibo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dZv1tpr12he"
      },
      "outputs": [],
      "source": [
        "# Create track dataframe containing only the necessary track.csv columns \n",
        "# df_tracks = df_tracks[[\n",
        "#     ('set', 'split'), \n",
        "#     ('set', 'subset'),\n",
        "#     ('track', 'genre_top'),\n",
        "# ]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for fma_small specific music tracks only\n",
        "df_tracks = df_tracks.loc[filter_small]\n",
        "df_features = df_features.loc[filter_small]"
      ],
      "metadata": {
        "id": "e5wLzI7I9gFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge echonest features\n",
        "# df_features = df_features.join(df_echonest, how='inner').sort_index(axis=1)"
      ],
      "metadata": {
        "id": "PlJPnLxSAett"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAujdtklX_Hb"
      },
      "outputs": [],
      "source": [
        "# Split datasets into training, validation, testing sets.\n",
        "\n",
        "# Note: While this is a preprocessing stage step it is \n",
        "# intentionally done early here (before exploratory data analysis) to guard \n",
        "# against Data Snooping Bias. By hiding validation and test data and only exploring \n",
        "# training data, we avoid stumbling upon interesting test set patterns which could \n",
        "# bias towards optimistic generalization error estimates.\n",
        "df_tracks_train = df_tracks[filter_train]\n",
        "df_tracks_validation = df_tracks[filter_val]\n",
        "df_tracks_test = df_tracks[filter_test]\n",
        "df_features_train = df_features.loc[filter_train]\n",
        "df_features_val = df_features.loc[filter_val]\n",
        "df_features_test = df_features.loc[filter_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tracks.info()"
      ],
      "metadata": {
        "id": "sDUTt3Jw7nYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ai-eYXoj9O7"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "The raw dataset is provided by FMA and is composed from 3 separate files:\n",
        "\n",
        "* tracks.csv\n",
        "* features.csv\n",
        "* echonest.csv\n",
        "\n",
        "Source: fma_metadata.zip from https://github.com/mdeff/fma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luDkDeQ9mqm_"
      },
      "source": [
        "### General\n",
        "\n",
        "This sub-section aims to gain a general understanding of the raw data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgtysBxyhBsV"
      },
      "source": [
        "##### Tracks Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep training set pristine; make copy solely for data exploration\n",
        "df_tracks_exploration = df_tracks_train.copy()"
      ],
      "metadata": {
        "id": "g7BY0E0iubYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7uiSb12VhYG"
      },
      "outputs": [],
      "source": [
        "# Shows that FMA features in tracks.csv are organised (via MultiIndex) in a top \n",
        "# and sub property hierarchy, arranged as tuples\n",
        "# e.g album has \"sub-features\" comments, date_created, ..., tags, etc\n",
        "df_tracks_exploration.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SVnl8l2Xl97"
      },
      "outputs": [],
      "source": [
        "df_tracks_exploration.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev81ApuBvAoI"
      },
      "outputs": [],
      "source": [
        "df_tracks_exploration.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5b_rwh4lNRE"
      },
      "outputs": [],
      "source": [
        "# Show general structure, values and data types of properties for each track.\n",
        "df_tracks_exploration.head()\n",
        "\n",
        "# Interpretation: tracks.csv contains metadata on each track. Some attributes \n",
        "# could serve as features (e.g tags, artist), but these will not be used for \n",
        "# training as the project goal is to classify based on the music itself. \n",
        "\n",
        "# Only 'genre_top' (which is applicable for our FMA dataset size choice) will \n",
        "# be used via a later track_id join with features.csv, serving as our target \n",
        "# output variable y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UmKZ9FZX_Hc"
      },
      "outputs": [],
      "source": [
        "# df_tracks_exploration.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vM_GDPTH2MU"
      },
      "outputs": [],
      "source": [
        "# Display top level genres are 8 balanced genre classes\n",
        "df_tracks_exploration['track']['genre_top'].hist(bins=50, figsize=(15, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlvATjbKhOsY"
      },
      "source": [
        "##### Features Dataset\n",
        "\n",
        "This section explores features.csv."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tracks_exploration.columns"
      ],
      "metadata": {
        "id": "y38ZyPXt0H7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.columns"
      ],
      "metadata": {
        "id": "H39JqaqA0UZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzG2mziqWGRq"
      },
      "outputs": [],
      "source": [
        "df_features.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut-_WHHRXr7q"
      },
      "outputs": [],
      "source": [
        "df_features.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oLO2GA9IkMx"
      },
      "outputs": [],
      "source": [
        "# Display top level features\n",
        "df_features.columns.levels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqmBzA-0joPQ"
      },
      "outputs": [],
      "source": [
        "# Shows each audio feature is sub-featured in terms of a statistical measure, such as kurtosis and skew.\n",
        "list(df_features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzLBUz3K3p1M"
      },
      "outputs": [],
      "source": [
        "df_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zUQNGea32Ww"
      },
      "outputs": [],
      "source": [
        "df_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FL4iiFuYLPh"
      },
      "outputs": [],
      "source": [
        "df_features['tonnetz'].hist(figsize=(25,15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKP0niJINO9j"
      },
      "outputs": [],
      "source": [
        "# attributes = [\"median_house_ value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
        "# scatter_matrix(features[attributes], figsize=(12, 8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM0wf2zGxN5E"
      },
      "outputs": [],
      "source": [
        "df_tracks_exploration['set']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVKoyh5JoUDe"
      },
      "outputs": [],
      "source": [
        "df_mfcc = df_features['mfcc']\n",
        "df_mfcc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8Eb79QToYbs"
      },
      "outputs": [],
      "source": [
        "df_mfcc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg9gh41Soais"
      },
      "outputs": [],
      "source": [
        "small = df_tracks['set', 'subset'] <= 'small'\n",
        "genre_Instrumental = df_tracks['track', 'genre_top'] == 'Instrumental'\n",
        "genre2_HH = df_tracks['track', 'genre_top'] == 'Hip-Hop'\n",
        "\n",
        "print(small.shape, genre_Instrumental.shape, genre2_HH.shape)\n",
        "\n",
        "X = df_features.loc[small & (genre_Instrumental | genre2_HH), 'mfcc']\n",
        "X = skl.decomposition.PCA(n_components=2).fit_transform(X)\n",
        "\n",
        "y = df_tracks.loc[small & (genre_Instrumental | genre2_HH), ('track', 'genre_top')]\n",
        "y = skl.preprocessing.LabelEncoder().fit_transform(y)\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c=y, cmap='RdBu', alpha=0.5)\n",
        "plt.show()\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu_alJXho7Le"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PiJylyeo-et"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA-L9EEHpCBb"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgd6olYQry7C"
      },
      "outputs": [],
      "source": [
        "# features_corr_matrix = features.corr()\n",
        "# features_corr_matrix['tonnetz'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YogaJfYurxV_"
      },
      "source": [
        "#### Pairwise Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1sDMWTKpD2R"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJlgnn-SmzSk"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQOcLfnM0-zd"
      },
      "source": [
        "### General"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u105yAWT1EAe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1n_FM1QC8Ze"
      },
      "outputs": [],
      "source": [
        "# Random seed for repeated execution reproducibility \n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrPdpBVQsFE8"
      },
      "outputs": [],
      "source": [
        "genres = list(LabelEncoder().fit(df_tracks['track', 'genre_top']).classes_)\n",
        "print('Genres ({}): {}'.format(len(genres), genres))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPW0BaydQLwJ"
      },
      "outputs": [],
      "source": [
        "def preprocess_pipeline(tracks, features, columns):\n",
        "    # Encode each genre with an integer\n",
        "    enc = LabelEncoder()\n",
        "    genres = tracks['track', 'genre_top']\n",
        "\n",
        "    # Split into training, validation and testing sets\n",
        "    y_train = enc.fit_transform(genres[df_train])\n",
        "    y_val = enc.transform(genres[df_val])\n",
        "    y_test = enc.transform(genres[df_test])\n",
        "    X_train = df_features.loc[df_train, columns].values\n",
        "    X_val = df_features.loc[df_val, columns].values\n",
        "    X_test = df_features.loc[df_test, columns].values\n",
        "    X_train, y_train = shuffle(X_train, y_train, random_state=RANDOM_SEED)\n",
        "    \n",
        "    # Standardize features, removing mean (to 0) and scaling to unit variance.\n",
        "    scaler = StandardScaler(copy=False)\n",
        "    scaler.fit_transform(X_train)\n",
        "    scaler.transform(X_val)\n",
        "    scaler.transform(X_test)\n",
        "    \n",
        "    return y_train, y_val, y_test, X_train, X_val, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMF3UCCxqorU"
      },
      "outputs": [],
      "source": [
        "df_train = df_tracks_train.index\n",
        "df_val = df_tracks_validation.index\n",
        "df_test = df_tracks_test.index\n",
        "\n",
        "print('Dataset split: {} training, {} validation, {} testing'.format(*map(len, [df_train, df_val, df_test])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjjBJQaasom2"
      },
      "source": [
        "### Spectrograms (For CRNN Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw6HPJEiqEvO"
      },
      "outputs": [],
      "source": [
        "def get_audio_path(audio_dir, track_id):\n",
        "    tid_str = '{:06d}'.format(track_id)\n",
        "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
        "\n",
        "\"\"\"\n",
        "Get track IDs from the mp3s in a directory.\n",
        "\"\"\"\n",
        "def get_trackIDs_from_dir(audio_dir):\n",
        "    tids = []\n",
        "    for _, dirnames, files in os.walk(audio_dir):\n",
        "        if dirnames == []:\n",
        "            tids.extend(int(file[:-4]) for file in files)\n",
        "    return tids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5wLqZTzqYqT"
      },
      "outputs": [],
      "source": [
        "track_ids = get_trackIDs_from_dir(f\"{INPUT_DIR}/fma_small\")\n",
        "len(track_ids)  # should return 8 * 1000 = 8000, 1000 songs per genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEuJaevIr0sH"
      },
      "outputs": [],
      "source": [
        "keep_cols = [\n",
        "    ('set', 'split'),\n",
        "    ('set', 'subset'),\n",
        "    ('track', 'genre_top')\n",
        "]\n",
        "\n",
        "filepath = 'input/fma_metadata/tracks.csv'\n",
        "tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
        "df_all = tracks[keep_cols]\n",
        "df_all = df_all[df_all[('set', 'subset')] == 'small']\n",
        "\n",
        "df_all['track_id'] = df_all.index\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrOUd88Ds8SS"
      },
      "outputs": [],
      "source": [
        "grouped_df = df_all.groupby(('track', 'genre_top')).first().reset_index()\n",
        "grouped_df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocPnz790uSFN"
      },
      "outputs": [],
      "source": [
        "def plot_spectogram(track_id, genre):\n",
        "    filename = get_audio_path(f\"{INPUT_DIR}/fma_small\", track_id)\n",
        "    y, sr = librosa.load(filename)\n",
        "    print(len(y),sr)\n",
        "    spect = librosa.feature.melspectrogram(y=y, sr=sr,n_fft=2048, hop_length=1024)\n",
        "    spect = librosa.power_to_db(spect, ref=np.max)\n",
        "    print(spect.shape, genre)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(spect, y_axis='mel', fmax=8000, x_axis='time')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title(str(genre))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIbLVpe70zqQ"
      },
      "outputs": [],
      "source": [
        "plot_spectogram(2, 'Hip-Hop') # Create spectogram for track 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ClyBkkluTxp"
      },
      "outputs": [],
      "source": [
        "# Visualize differences in spectrograms for each genre\n",
        "for index, row in grouped_df.iterrows():\n",
        "    track_id = int(row['track_id'])\n",
        "    genre = row[('track', 'genre_top')]\n",
        "    plot_spectogram(track_id, genre)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYl2FY_4DCgP"
      },
      "source": [
        "### Spectrogram for All Files (For LSTM model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXO2f6ZpRl9R"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Read and convert file into melspectrogram, return as numpy array\n",
        "'''\n",
        "def read_convert_melspec(file_name,title = None):\n",
        "  try:\n",
        "    x,sr = librosa.load(file_name,sr = None)\n",
        "  except:\n",
        "    print(f\"Can't read {file_name}\")\n",
        "    return None\n",
        "\n",
        "  if title is None:\n",
        "    title = file_name[:-4]\n",
        "  spect = librosa.feature.melspectrogram(y=x, sr=sr,n_fft=2048, hop_length=1024)\n",
        "  spect = librosa.power_to_db(spect, ref=np.max)\n",
        "  return spect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUUkN1OJPXB3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Read and store all file path and store in a list\n",
        "'''\n",
        "def read_all_file():\n",
        "  total_audio_list = []\n",
        "  for i in range(156):\n",
        "    if i < 10:\n",
        "      string = \"00\"+str(i)\n",
        "    elif i < 100:\n",
        "      string = \"0\"+str(i)\n",
        "    else :\n",
        "      string = str(i)\n",
        "    list_file = glob.glob(f\"{INPUT_DIR}/fma_small/{string}/*.mp3\")\n",
        "    total_audio_list.extend(list_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKMtomTCQzsh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Assign audio from all directory to each genre group, based on the csv file\n",
        "'''\n",
        "def assign_audio_to_genre(total_audio_list,top_genre):\n",
        "  seperate_genre_dict = {}\n",
        "  for i in top_genre:\n",
        "    seperate_genre_dict[i] = []\n",
        "\n",
        "  for i in total_audio_list:\n",
        "    for j in seperate_genre_dict.keys():\n",
        "      try:\n",
        "        if tracks[('track', 'genre_top')][int(i[-10:-4].lstrip('0'))] == j:\n",
        "          seperate_genre_dict[j].append(i)\n",
        "          continue\n",
        "      except Exception as e:\n",
        "        print(f\"Exception {e}and the string is {i}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55iRbKUtDPN5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "preprocess data and store them into hdf5 file\n",
        "'''\n",
        "def write_genre_hdf(genre_list,genre_name):\n",
        "  list_store = []\n",
        "  for i in genre_list:\n",
        "    converted = read_convert_melspec(i)\n",
        "    if converted is None:\n",
        "      continue\n",
        "    temp = {\"name\":i,\"mel_spec\":converted}\n",
        "\n",
        "    list_store.append(temp)\n",
        "\n",
        "  file_name = \"mel_spec/\"+genre_name+\".hdf5\"\n",
        "\n",
        "  h = h5py.File(file_name, 'w')\n",
        "  group = h.create_group(genre_name)\n",
        "  for item in list_store:\n",
        "\n",
        "    group.create_dataset(item[\"name\"].replace(\"/\",\"-\"),data = item[\"mel_spec\"])\n",
        "  h.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1zIQj0fR7y7"
      },
      "outputs": [],
      "source": [
        "genre_list = df_tracks['track']['genre_top']\n",
        "total_audio_list = read_all_file()\n",
        "separate_genre_dict = assign_audio_to_genre(total_audio_list, genre_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8axxfrLIG9B"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Convert all to json file, there will be a file for each music genre\n",
        "'''\n",
        "for keys, values in list(separate_genre_dict.items):\n",
        "    write_genre_hdf(values, keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0-KORe8HNf6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Reading the data out,\n",
        "return a list of dictionary, each dictionary contains the name and preprocessed data\n",
        "'''\n",
        "def read_hdf(file_path):\n",
        "    return_dict = []\n",
        "    with h5py.File(file_path, 'r') as hf:\n",
        "        print(list(hf.keys()))\n",
        "        dataset = hf[file_path[9:-5]]\n",
        "        print(len(list(dataset.keys())))\n",
        "        keys = list(dataset.keys())\n",
        "        for i in keys:\n",
        "            return_dict.append({\n",
        "                \"name\":i.replace(\"-\",\"/\"),\n",
        "                \"data\":dataset[i][:]\n",
        "            })\n",
        "        return return_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGOoZb7TppDW"
      },
      "source": [
        "# Model Selection, Tuning and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb_tm2djqo-5"
      },
      "source": [
        "### Baseline (Classical ML)\n",
        "\n",
        "This purpose of this section is to implement a variety of machine learning models, which are then used as a baseline for performance comparison with neural network based classifiers to follow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlNN_N5KqV8Z"
      },
      "outputs": [],
      "source": [
        "# List of classical machine learning model candidates to use as baseline\n",
        "classifiers = {\n",
        "    'LR': LogisticRegression(max_iter=10000),\n",
        "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
        "    # 'SVCrbf': SVC(kernel='rbf', max_iter=10000),\n",
        "    # 'SVCpoly1': SVC(kernel='poly', degree=1, max_iter=10000),\n",
        "    # 'linSVC1': SVC(kernel=\"linear\", max_iter=10000),\n",
        "    # 'linSVC2': LinearSVC(),\n",
        "    # 'DT': DecisionTreeClassifier(max_depth=5),\n",
        "    # 'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    # 'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
        "    # 'NB': GaussianNB(),\n",
        "}\n",
        "\n",
        "# TODO: Improve this by using subsets per: \"Index(['chroma_cens', 'chroma_cqt', 'chroma_stft', 'mfcc', 'rmse',\n",
        "      #  'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast',\n",
        "      #  'spectral_rolloff', 'tonnetz', 'zcr'],\n",
        "feature_subsets = {}\n",
        "for subset in df_features.columns.levels[0]:\n",
        "    feature_subsets[subset] = subset\n",
        "    feature_subsets.update({\n",
        "        'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
        "        'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
        "        'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
        "        'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
        "        'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
        "        # 'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
        "        # 'all': list(df_features.columns.levels[0])\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make columns represent each model candidate\n",
        "baseline_models = list(classifiers.keys())\n",
        "# Add a column to show number of features used\n",
        "baseline_models = baseline_models.insert(0, 'numFeatures')\n",
        "\n",
        "# Setup dataframe to show scores in a matrix, with models as columns and \n",
        "# feature subsets as rows\n",
        "acc_scores_matrix = pd.DataFrame(columns=baseline_models, index=feature_subsets.keys())\n",
        "for fsubset_name, fsubset in tqdm.notebook.tqdm(feature_subsets.items(), desc='feature subset'):\n",
        "  y_train, y_val, y_test, X_train, X_val, X_test = preprocess_pipeline(df_tracks, df_features, fsubset)\n",
        "\n",
        "  acc_scores_matrix.loc[fsubset_name, 'numFeatures'] = X_train.shape[1]\n",
        "  for clf_name, clf in classifiers.items(): \n",
        "      clf.fit(X_train, y_train)\n",
        "      score = clf.score(X_test, y_test)\n",
        "      acc_scores_matrix.loc[fsubset_name, clf_name] = score\n",
        "      y_pred = clf.predict(X_test)\n",
        "      "
      ],
      "metadata": {
        "id": "yIhTJjma0kTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function, highlights the top scoring for each feature subset in model-feature matrix\n",
        "def format_matrix_scores(scores):\n",
        "    def highlight(s):\n",
        "        is_max = s == max(s[1:])\n",
        "        return ['background-color: green' if v else '' for v in is_max]\n",
        "    scores = scores.style.apply(highlight, axis=1)\n",
        "    return scores.format('{:.1%}', subset = pd.IndexSlice[:, scores.columns[1]:])"
      ],
      "metadata": {
        "id": "TumkpIkUr78V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S3pCNLMrHQx"
      },
      "outputs": [],
      "source": [
        "# TODO: Uncomment only when required as this runs 10+ models for 518 features\n",
        "# acc_scores = run_baseline_models_vs_feature_subsets(classifiers, feature_sets)\n",
        "ipd.display(format_matrix_scores(acc_scores_matrix))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRU0heUYrIcn"
      },
      "source": [
        "### Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsHc8WEzew6N"
      },
      "source": [
        "#### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCtoVmp4rkD6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZA95BPwreaZ"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHpk66Aprk43"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjWWZPsRrR3b"
      },
      "source": [
        "#### Transfer Learning Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjNk4Oi1rldD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiOPbUyKrZF7"
      },
      "source": [
        "#### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLQ91rkqrmuE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOSf99sx5IyT"
      },
      "source": [
        "#### CRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXTrv3735N5M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from os.path import isfile\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\n",
        "\n",
        "from keras import backend\n",
        "from keras.layers import ELU\n",
        "from keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-Wqs1jO5QyE"
      },
      "outputs": [],
      "source": [
        "genres_dict = {\n",
        "    'Electronic': 0, \n",
        "    'Experimental': 1, \n",
        "    'Folk': 2, \n",
        "    'Hip-Hop': 3, \n",
        "    'Instrumental': 4,\n",
        "    'International': 5, \n",
        "    'Pop': 6, \n",
        "    'Rock': 7  \n",
        "}\n",
        "\n",
        "reverse_genres_dic = {v: k for k, v in genres_dict.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iaVr0nU52a-"
      },
      "outputs": [],
      "source": [
        "npz_file = np.load('input/shuffled_train.npz')\n",
        "# print(npz_file.files)\n",
        "X_train = npz_file['arr_0'] # get array from the first file \n",
        "y_train = npz_file['arr_1'] # get array from the second file\n",
        "print(X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_xb4RqIZ-VX"
      },
      "outputs": [],
      "source": [
        "npz_valid_file = np.load('input/shuffled_valid.npz')\n",
        "# print(npz_valid_file.files)\n",
        "X_valid = npz_valid_file['arr_0']\n",
        "y_valid = npz_valid_file['arr_1']\n",
        "print(X_valid.shape, y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHOTnEho54cj"
      },
      "outputs": [],
      "source": [
        "# Check by plotting a Spectogram\n",
        "num = 5300\n",
        "spectogram = X_train[num]\n",
        "genre_index = np.argmax(y_train[num])\n",
        "\n",
        "print(reverse_genres_dic[genre_index])\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "librosa.display.specshow(spectogram.T, y_axis='mel', x_axis='time')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Test Melspectogram')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaWdXMMlZciQ"
      },
      "source": [
        "##### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uEf8ueXZhnt"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 8   # 8 genres classes in total\n",
        "n_features = X_train.shape[2]\n",
        "n_time = X_train.shape[1]\n",
        "N_LAYERS = 3\n",
        "FILTER_LENGTH = 5\n",
        "CONV_FILTER_COUNT = 56\n",
        "BATCH_SIZE = 32\n",
        "LSTM_COUNT = 96\n",
        "EPOCH_COUNT = 70\n",
        "NUM_HIDDEN = 64\n",
        "L2_regularization = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKLuoIChZibP"
      },
      "outputs": [],
      "source": [
        "def conv_recurrent_model_build(model_input):\n",
        "    print('Building model...')\n",
        "    layer = model_input\n",
        "    \n",
        "    ### 3 1D Convolution Layers\n",
        "    for i in range(N_LAYERS):\n",
        "        # give name to the layers\n",
        "        layer = Conv1D(\n",
        "                filters=CONV_FILTER_COUNT,\n",
        "                kernel_size=FILTER_LENGTH,\n",
        "                kernel_regularizer=regularizers.l2(L2_regularization),  # Tried 0.001\n",
        "                name='convolution_' + str(i + 1)\n",
        "            )(layer)\n",
        "        layer = BatchNormalization(momentum=0.9)(layer)\n",
        "        layer = Activation('relu')(layer)\n",
        "        layer = MaxPooling1D(2)(layer)\n",
        "        layer = Dropout(0.4)(layer)\n",
        "    \n",
        "    ## LSTM Layer\n",
        "    layer = LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    \n",
        "    ## Dense Layer\n",
        "    layer = Dense(NUM_HIDDEN, kernel_regularizer=regularizers.l2(L2_regularization), name='dense1')(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    \n",
        "    ## Softmax Output\n",
        "    layer = Dense(num_classes)(layer)\n",
        "    layer = Activation('softmax', name='output_realtime')(layer)\n",
        "    model_output = layer\n",
        "    model = Model(model_input, model_output)\n",
        "    \n",
        "    \n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model.compile(\n",
        "            loss='categorical_crossentropy',\n",
        "            optimizer=opt,\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "    \n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVT5xm4Zqxi"
      },
      "outputs": [],
      "source": [
        "def train_model(x_train, y_train, x_val, y_val):\n",
        "    \n",
        "    n_features = x_train.shape[2]\n",
        "    input_shape = (None, n_features)\n",
        "    model_input = Input(input_shape, name='input')\n",
        "    \n",
        "    model = conv_recurrent_model_build(model_input)\n",
        "    \n",
        "#     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
        "#                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
        "#                               embeddings_metadata=None)\n",
        "    checkpoint_callback = ModelCheckpoint('./models/crnn/weights.best.h5', monitor='val_acc', verbose=1,\n",
        "                                          save_best_only=True, mode='max')\n",
        "    \n",
        "    reducelr_callback = ReduceLROnPlateau(\n",
        "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
        "                verbose=1\n",
        "            )\n",
        "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
        "\n",
        "    # Fit the model and get training history.\n",
        "    print('Training...')\n",
        "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
        "                        validation_data=(x_val, y_val), verbose=1, callbacks=callbacks_list)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhXv984ZZ1IK"
      },
      "outputs": [],
      "source": [
        "model, history  = train_model(X_train, y_train, X_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDx861e-Z2gk"
      },
      "outputs": [],
      "source": [
        "def show_summary_stats(history):\n",
        "    # List all data in history\n",
        "    print(history.history.keys())\n",
        "\n",
        "    # Summarize history for accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAWw5bXt35pM"
      },
      "outputs": [],
      "source": [
        "show_summary_stats(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMV5VnW9fjYs"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRQdWrs-38v3"
      },
      "outputs": [],
      "source": [
        "y_true = np.argmax(y_valid, axis = 1)\n",
        "y_pred = model.predict(X_valid)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "labels = [0,1,2,3,4,5,6,7]\n",
        "target_names = genres_dict.keys()\n",
        "\n",
        "print(y_true.shape, y_pred.shape)\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htXkj-SE3-ha"
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f6Cf4kM6ZaC"
      },
      "source": [
        "# Summary, Insights and Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIlRCEoZ6ei4"
      },
      "source": [
        "TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}