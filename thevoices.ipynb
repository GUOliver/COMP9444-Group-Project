{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a0199c-e0c1-4aa6-ae83-8f29d8d4c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Country', 'Instrumental', 'Old-Time / Historic', 'Electronic', 'International', 'Rock', 'Jazz', 'Spoken', 'Classical', 'Folk', 'Hip-Hop', 'Experimental', 'Soul-RnB', 'Easy Listening', 'Blues', 'Pop'}\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from RecurrentNet import RecurrentNet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filepath2 = \"D:\\\\MLdata\\\\tracks.csv\"\n",
    "data2 = pd.read_csv(filepath2, index_col=0, header=[0,1])\n",
    "y_col = data2.loc[:,( 'track', 'genre_top')].replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
    "classes = set(y_col)\n",
    "print(set(y_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dacb114-3994-466e-92b0-63c89087a1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d9e822-d01b-4e52-8bd2-1d4ce65e5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def read_hdf(file_path):\n",
    "    return_dict = []\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        #print(list(hf.keys()))\n",
    "        dataset = hf[file_path[9:-5]]\n",
    "        #print(len(list(dataset.keys())))\n",
    "        keys = list(dataset.keys())\n",
    "        for i in keys:\n",
    "            return_dict.append({\n",
    "                \"name\":int(i.replace(\"-\",\"/\")[-10:-4]),\n",
    "                \"data\":dataset[i][:]\n",
    "            })\n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b531a8-bee2-4e15-a2ec-c06ba0521ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    " \n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RecurrentNet(torch.nn.Module):\n",
    "    def __init__(self, n_layers, seq_size, dropout, netType, n_inputs, n_outputs):\n",
    "        super(RecurrentNet, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.seq_size = seq_size\n",
    "        if netType == 'LSTM':\n",
    "            self.rec = nn.LSTM(n_inputs, seq_size, n_layers, dropout = dropout)\n",
    "        if netType == 'GRU':\n",
    "            self.rec = nn.GRU(n_inputs, seq_size, n_layers, dropout = dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden1 = nn.Linear(seq_size, seq_size)\n",
    "        self.hidden2 = nn.Linear(seq_size, int(seq_size/2))\n",
    "        self.output = nn.Linear(int(seq_size/2), n_outputs)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rec(x) \n",
    "        out = self.relu(self.hidden1(out))\n",
    "        out = self.relu(self.hidden2(out))\n",
    "        out = self.output(out) \n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9181bc4d-b5de-41b6-bfb5-8e6af8759f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1999\n",
      "2999\n",
      "3998\n",
      "4998\n",
      "5995\n",
      "6994\n",
      "7994\n",
      "118891\n",
      "853\n",
      "73585\n",
      "106567\n",
      "8\n",
      "{'name': 118891, 'data': array([[-38.719635, -58.235054, -53.233833, ..., -53.98723 , -53.17541 ,\n",
      "        -51.428055],\n",
      "       [-33.896454, -54.301975, -44.54223 , ..., -47.041042, -51.893463,\n",
      "        -47.236473],\n",
      "       [-28.294024, -33.407738, -33.531178, ..., -40.570015, -37.3398  ,\n",
      "        -36.14995 ],\n",
      "       ...,\n",
      "       [-65.35934 , -56.610107, -44.424347, ..., -66.03724 , -61.50744 ,\n",
      "        -64.33018 ],\n",
      "       [-72.74361 , -63.917946, -47.802277, ..., -69.01964 , -64.23512 ,\n",
      "        -69.64878 ],\n",
      "       [-80.      , -80.      , -63.335968, ..., -79.2271  , -74.57732 ,\n",
      "        -77.94803 ]], dtype=float32)}\n",
      "128\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "x_data = []\n",
    "\n",
    "\n",
    "#print(type(data))\n",
    "n_outputs = 0\n",
    "for k in classes:\n",
    "    try:\n",
    "        x_data.extend(read_hdf(\"D:/MLdata/\" + k + \".hdf5\"))\n",
    "        print(len(x_data))\n",
    "        n_outputs += 1\n",
    "    except:\n",
    "        pass\n",
    "random.shuffle(x_data)\n",
    "print(x_data[0]['name'])\n",
    "print(x_data[2]['name'])\n",
    "print(x_data[65]['name'])\n",
    "print(x_data[17]['name'])\n",
    "print(n_outputs)\n",
    "shape1 = len(x_data[0]['data'])\n",
    "print((x_data[0]))\n",
    "shape2 = len(x_data[0]['data'][0])\n",
    "print(shape1)\n",
    "print(shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad72b9b-c0d5-4aad-9a8e-1ad691c3a7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526134a4-64b1-485c-85f4-9abe6f74c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock\n"
     ]
    }
   ],
   "source": [
    "y_data = []\n",
    "x_values = []\n",
    "for i in x_data:\n",
    "    y_data.append(y_col[i['name']])\n",
    "    #x_values.append(i['data'].flatten())\n",
    "    x_values.append((i['data']).flatten())\n",
    "print(y_data[300])\n",
    "#print(x_values[300][-5:-1])\n",
    "#print(x_values[350][-5:-1])\n",
    "#print(x_values[10][-5:-1])\n",
    "#print(x_values[1000][-5:-1])\n",
    "#print(len(x_values))\n",
    "#for k in range(20):\n",
    "#    for j in range(20):\n",
    "#        print(len(x_values[k][j]))\n",
    "#print(len(x_values[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacecd30-4746-4541-aecb-23b947c14ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7994\n",
      "[-38.719635 -58.235054 -53.233833 ... -79.2271   -74.57732  -77.94803 ]\n",
      "82688\n"
     ]
    }
   ],
   "source": [
    "print(len(x_values))\n",
    "print(x_values[0])\n",
    "print(len(x_values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd076d5-e8f9-4ee4-a40e-a9c6120fcc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73451705 0.70670815 0.69438424 ... 0.         0.         0.08343067]\n",
      "[[2]\n",
      " [4]\n",
      " [5]\n",
      " ...\n",
      " [3]\n",
      " [6]\n",
      " [7]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "[[0.59008293 0.62056904 0.63030612 ... 0.85129797 0.72675152 0.71318529]\n",
      " [0.60648689 0.70120623 0.70341125 ... 0.90419723 0.86546805 0.92969959]\n",
      " [0.65913885 0.66464627 0.65813429 ... 0.95820048 0.97592499 0.96154034]\n",
      " ...\n",
      " [0.28788214 0.2565033  0.         ... 0.45552707 0.35614147 0.30340624]\n",
      " [0.         0.         0.         ... 0.43655949 0.41584411 0.34932985]\n",
      " [0.         0.         0.         ... 0.28637819 0.25517778 0.17092018]]\n",
      "[0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "#x_col = x_data.to_numpy()\n",
    "#print(len(y_col))\n",
    "#print(len(x_col))\n",
    "#print(len(x_col[0]))\n",
    "#classes = set(y_col)\n",
    "#print(len(classes))\n",
    "\n",
    "#flatten x to normalize then unflatten\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x_values)\n",
    "print(x_scaled[1])\n",
    "x_values = np.reshape(x_scaled, (len(x_values),shape1,shape2))\n",
    "\n",
    "y_data = label_encoder.fit_transform(np.ravel(y_data))\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "print(y_data)\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "# transform data\n",
    "onehot_y = encoder.fit_transform(y_data)\n",
    "print(onehot_y)\n",
    "#print(y_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_values , onehot_y,  test_size=0.2, random_state=42)\n",
    "print(X_train[3])\n",
    "print(y_train[3])\n",
    "X_train, X_test, y_train, y_test = tf.convert_to_tensor(X_train), tf.convert_to_tensor(X_test), tf.convert_to_tensor(y_train), tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1aafbc-0fdb-4845-92e9-20bfd8dcab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7994\n",
      "[[0.51600456 0.27206182 0.33457708 ... 0.32515965 0.33530735 0.35714931]\n",
      " [0.57629433 0.32122531 0.44322214 ... 0.41198697 0.35133171 0.40954409]\n",
      " [0.64632471 0.58240328 0.58086028 ... 0.49287481 0.53325248 0.54812565]\n",
      " ...\n",
      " [0.18300829 0.29237366 0.44469566 ... 0.17453451 0.23115702 0.19587278]\n",
      " [0.09070492 0.20102568 0.40247154 ... 0.13725452 0.19706097 0.12939024]\n",
      " [0.         0.         0.2083004  ... 0.00966129 0.06778355 0.02564964]]\n",
      "128\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "print(len(x_values))\n",
    "print(x_values[0])\n",
    "print(len(x_values[0]))\n",
    "print(len(x_values[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b1bcbb-1847-4058-b852-8ab334a2aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def testAccuracy(model):\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            audio, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(audio)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, num_epochs):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (audio, labels) in enumerate(train_loader, 0):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(audio)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            \n",
    "        accuracy = testAccuracy()\n",
    "        print('epoch:', epoch+1,' test accuracy: %d %%' % (accuracy))\n",
    "        \n",
    "net = RecurrentNet(n_layers = 3, seq_size = 5, dropout = 0.2, netType = 'LSTM', \n",
    "                   n_inputs = len(x_values[0]), n_outputs = n_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a852cb-9290-4c14-88bf-cd2bbca061b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m num_input \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m train_loader  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_dataset,\n\u001b[0;32m      7\u001b[0m                                  batch_size\u001b[38;5;241m=\u001b[39mtrain_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlr,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m)\n",
      "File \u001b[1;32mD:\\python\\lib\\site-packages\\torch\\utils\\data\\dataset.py:184\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[1;32mD:\\python\\lib\\site-packages\\torch\\utils\\data\\dataset.py:184\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not callable"
     ]
    }
   ],
   "source": [
    "num_input = X_train.shape[1] - 1\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset,\n",
    "                                 batch_size=train_dataset.__len__())\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=args.lr,weight_decay=0.00001)\n",
    "\n",
    "    # training loop\n",
    "epoch = 0\n",
    "count = 0\n",
    "while epoch < args.epoch and count < 2000:\n",
    "    epoch = epoch+1\n",
    "    accuracy = train(net, train_loader, optimizer)\n",
    "    if accuracy == 100:\n",
    "        count = count+1\n",
    "    else:\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a62a00-5fe3-4e69-867c-344cff11f9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.45392098 0.53642281 0.87305622 0.919807   0.90854712 0.89576116\n",
      " 0.80745203 0.59096985 0.399822   0.33548942 0.33107905 0.72995231\n",
      " 0.6384782  0.64631622 0.55251147 0.53183699 0.43713722 0.7987641\n",
      " 0.94692576 0.9002331  0.83657439 0.86084158 0.84373007 0.82863815\n",
      " 0.80754285 0.81094761 0.80336809 0.77991283 0.7270967  0.70747182\n",
      " 0.55035419 0.50194178 0.32349844 0.3278717  0.24007535 0.73611832\n",
      " 0.9903044  0.88814662 0.81768794 0.84914468 0.86010885 0.85183873\n",
      " 0.84212658 0.83039799 0.81253414 0.77431386 0.76249838 0.72717001\n",
      " 0.62205486 0.57073793 0.43446999 0.4107261  0.47151752 0.64850912\n",
      " 0.74312963 0.66387866 0.62960482 0.56069593 0.48941584 0.52906961\n",
      " 0.64548564 0.52637811 0.48563375 0.40869226 0.47106519 0.58367348\n",
      " 0.95003483 0.888026   0.86240106 0.88486583 0.87162278 0.85514894\n",
      " 0.81588035 0.79895217 0.78648121 0.8547245  0.89500484 0.88597612\n",
      " 0.74998658 0.62407045 0.50840063 0.46380663 0.5571198  0.63780463\n",
      " 0.97781415 0.95768332 0.95126901 0.91500276 0.82159889 0.80924748\n",
      " 0.94505515 0.90210788 0.89659667 0.89405642 0.79682803 0.68176754\n",
      " 0.61663001 0.58927727 0.49080977 0.91615367 0.90014462 0.89670432\n",
      " 0.8664516  0.72128905 0.58222747 0.64801843 0.61300123 0.71893888\n",
      " 0.78462415 0.63932862 0.61243088 0.65215588 0.55312643 0.59347181\n",
      " 0.93148084 0.8841073  0.8228781  0.83781843 0.83770018 0.84230804\n",
      " 0.8377954  0.81452751 0.79761631 0.76853967 0.73044918 0.70365431\n",
      " 0.65216231 0.58012071 0.55368476 0.3597538  0.39122529 0.3063096\n",
      " 0.93650327 0.94470201 0.8530966  0.87121253 0.86462665 0.84599669\n",
      " 0.83227086 0.81484146 0.80623069 0.79167328 0.75836265 0.73983779\n",
      " 0.688304   0.5414403  0.51708865 0.30764141 0.24826894 0.20557575\n",
      " 0.72905216 0.59320316 0.61666572 0.51645679 0.45244541 0.44624999\n",
      " 0.60800526 0.60098956 0.47826867 0.40762224 0.28147163 0.25719352\n",
      " 0.82069057 0.90949767 0.85736709 0.83637455 0.84698501 0.83917391\n",
      " 0.83295097 0.8207386  0.79750028 0.86661983 0.92184067 0.88275418\n",
      " 0.87837071 0.76213279 0.51475384 0.80715208 0.84440243 0.33824568\n",
      " 0.74866788 0.99533963 0.96447487 0.94136763 0.90322509 0.86343398\n",
      " 0.88215952 0.90948658 0.91347382 0.90473182 0.91515193 0.70596638\n",
      " 0.67337964 0.59705108 0.54791894 0.73892498 0.93258679 0.91860232\n",
      " 0.90851638 0.8362417  0.53274727 0.44003754 0.51038642 0.37900925\n",
      " 0.66470659 0.71364625 0.57688182 0.58264046 0.53062787 0.42790618\n",
      " 0.69507952 0.98775787 0.88378248 0.82259121 0.84847715 0.84826729\n",
      " 0.84245813 0.82201014 0.81579442 0.81322205 0.80106335 0.76515765\n",
      " 0.71495767 0.55031813 0.539078   0.45589824 0.29812927 0.32069082\n",
      " 0.57829533 0.97320561 0.90632951 0.82536407 0.83169563 0.84696109\n",
      " 0.85191377 0.83334274 0.81960881 0.80435553 0.77431347 0.73847461\n",
      " 0.70653126 0.64268417 0.57971745 0.46209526 0.37058876 0.33071532\n",
      " 0.52455626 0.76862538 0.57859535 0.61602159 0.57999578 0.48751345\n",
      " 0.43403344 0.64386854 0.60894716 0.52451248 0.48196726 0.57696088\n",
      " 0.37055855 0.92821763 0.88128636 0.84812101 0.86160617 0.85413752\n",
      " 0.83197498 0.81243789 0.79658306 0.78623731 0.84394414 0.9085911\n",
      " 0.91725132 0.86946552 0.6182811  0.45950828 0.23198805 0.33849459\n",
      " 0.34044027 0.93535261 0.97451692 0.93094735 0.939115   0.85870457\n",
      " 0.82371168 0.91204367 0.91981323 0.91475458 0.91012416 0.81510682\n",
      " 0.69504068 0.67027936 0.56832042 0.48290124 0.88583312 0.92270112\n",
      " 0.92286837 0.90290885 0.72495947 0.51213474 0.39799318 0.34376216\n",
      " 0.27288227 0.75848141 0.65485005 0.53649101 0.55945606 0.45501904\n",
      " 0.46832094 0.86988494 0.8847959  0.87278199 0.86429896 0.8745666\n",
      " 0.86654768 0.84980876 0.82998075 0.79655256 0.76116881 0.73765574\n",
      " 0.71022425 0.67901499 0.52616215 0.53778753 0.39523373 0.38109164\n",
      " 0.36118082 0.85884815 0.96351707 0.90664203 0.88325586 0.87943692\n",
      " 0.84135864 0.83663783 0.81460536 0.78757958 0.78970535 0.76417297\n",
      " 0.73403707 0.6993943  0.57131057 0.57920098 0.32347851 0.23127847\n",
      " 0.23208465 0.73220387 0.69730992 0.55567797 0.56300249 0.55620213\n",
      " 0.50558405 0.56673198 0.58047781 0.62843778 0.50281668 0.39428926\n",
      " 0.39696736 0.74064915 0.95520692 0.88322172 0.82209349 0.82350969\n",
      " 0.80693758 0.80990181 0.80731111 0.81137331 0.8152873  0.92410595\n",
      " 0.95424945 0.94757981 0.83319126 0.54128599 0.33990917 0.35862885\n",
      " 0.28257551 0.56744738 0.98120942 0.96594775 0.92504263 0.88873663\n",
      " 0.85659389 0.82515979 0.93900709 0.89014707 0.88286824 0.88146882\n",
      " 0.75556312 0.67712076 0.61114745 0.57536178 0.60496004 0.92821748\n",
      " 0.92075379 0.91445603 0.85178745 0.66171932 0.51522708 0.33372912\n",
      " 0.3194952  0.56336164 0.73530049 0.55764956 0.56765227 0.53223815\n",
      " 0.46436892 0.54802048 0.96630363 0.87930617 0.85877092 0.88390863\n",
      " 0.87794983 0.86713707 0.85870624 0.82026015 0.80768068 0.80311835\n",
      " 0.75647581 0.7228508  0.62411075 0.52901087 0.46933227 0.39216471\n",
      " 0.48483691 0.45133958 0.96153648 0.85826333 0.82622511 0.88786564\n",
      " 0.82140778 0.84318643 0.84012504 0.82964909 0.8187144  0.79492606\n",
      " 0.75665843 0.71848593 0.68060114 0.5724697  0.52244492 0.38770622\n",
      " 0.37120171 0.34627552 0.78944471 0.68021035 0.61483898 0.5837584\n",
      " 0.60175993 0.45987186 0.64998024 0.65178967 0.64790952 0.64519286\n",
      " 0.52691655 0.43848963 0.8982764  0.9081743  0.83177602 0.86402805\n",
      " 0.82284918 0.86291597 0.82998438 0.80592213 0.81795912 0.91818376\n",
      " 0.95869865 0.95635362 0.92184443 0.70027906 0.54736252 0.36968994\n",
      " 0.28670306 0.20480027 0.85527272 0.90792072 0.94951785 0.92808259\n",
      " 0.85862091 0.8590276  0.85029471 0.89263163 0.89884579 0.90235598\n",
      " 0.87955043 0.69487581 0.65097752 0.56787806 0.52948647 0.6992342\n",
      " 0.92600632 0.93229971 0.90988727 0.79207268 0.53908544 0.48169498\n",
      " 0.27909269 0.24481497 0.72284203 0.6587548  0.60380852 0.58601708\n",
      " 0.5189868  0.43844757 0.81489909 0.94929657 0.90325971 0.70499802\n",
      " 0.63191671 0.50431743 0.60196297 0.5641201  0.45315046 0.38882416\n",
      " 0.38513846 0.28334856 0.5613029  0.55232244 0.38044977 0.27615085\n",
      " 0.37187347 0.36860733 0.66079235 0.9155066  0.81354692 0.67437978\n",
      " 0.63093309 0.45609684 0.42752275 0.4005024  0.50326195 0.50213051\n",
      " 0.53146448 0.39592819 0.52660494 0.58147922 0.33118229 0.31312847\n",
      " 0.35751257 0.34560289 0.49068766 0.56507816 0.31778922 0.28888617\n",
      " 0.42243719 0.32484341 0.43779511 0.60422442 0.41598225 0.46633325\n",
      " 0.58732585 0.37347554 0.3287796  0.46903019 0.47971287 0.45125637\n",
      " 0.40458851 0.3502243  0.40454526 0.33496432 0.3486084  0.36929617\n",
      " 0.55788139 0.59119706 0.75051255 0.77097561 0.78516331 0.77140226\n",
      " 0.75144982 0.63791523 0.61955409 0.43783454 0.50797441 0.61982703\n",
      " 0.76519659 0.76253893 0.63289032 0.70247161 0.69946544 0.60828475\n",
      " 0.52051921 0.53384166 0.68117766 0.77022959 0.70999069 0.70755997\n",
      " 0.57426386 0.6572155  0.70358305 0.73949327 0.56270795 0.51977861\n",
      " 0.74851787 0.80955513 0.80355222 0.74066401 0.54521208 0.37858814\n",
      " 0.68920355 0.78403236 0.73650403 0.71194709 0.63171935 0.46641083\n",
      " 0.46824811 0.48864231 0.42965517 0.31036987 0.23900843 0.21731238\n",
      " 0.26433468 0.25233412 0.20357733 0.2357501  0.21000409 0.2892395\n",
      " 0.25667205 0.25442033 0.24520435 0.22847133 0.23227177 0.24369507\n",
      " 0.2332633  0.21836791 0.20826606 0.22765484 0.24204803 0.23859791\n",
      " 0.22429762 0.27808151 0.21385254 0.21975322 0.19103622 0.25034356\n",
      " 0.23505968 0.21930714 0.24591608 0.20608196 0.2634376  0.2436491\n",
      " 0.25487504 0.24365745 0.2158072  0.2392035  0.23913741 0.19716015\n",
      " 0.24917927 0.21588535 0.22901464 0.25662794], shape=(646,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf19170-eb28-49b6-8032-8bf6441781a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
