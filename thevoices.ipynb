{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a0199c-e0c1-4aa6-ae83-8f29d8d4c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Folk', 'Hip-Hop', 'Rock', 'Electronic', 'Old-Time / Historic', 'Easy Listening', 'Pop', 'Spoken', 'Blues', 'Soul-RnB', 'Country', 'Classical', 'Experimental', 'Instrumental', 'Jazz', 'International'}\n"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from RecurrentNet import RecurrentNet\n",
    "\n",
    "\n",
    "filepath2 = \"D:\\\\MLdata\\\\tracks.csv\"\n",
    "data2 = pd.read_csv(filepath2, index_col=0, header=[0,1])\n",
    "y_col = data2.loc[:,( 'track', 'genre_top')].replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
    "classes = set(y_col)\n",
    "print(set(y_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dacb114-3994-466e-92b0-63c89087a1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d9e822-d01b-4e52-8bd2-1d4ce65e5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def read_hdf(file_path):\n",
    "    return_dict = []\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        #print(list(hf.keys()))\n",
    "        dataset = hf[file_path[9:-5]]\n",
    "        #print(len(list(dataset.keys())))\n",
    "        keys = list(dataset.keys())\n",
    "        for i in keys:\n",
    "            return_dict.append({\n",
    "                \"name\":int(i.replace(\"-\",\"/\")[-10:-4]),\n",
    "                \"data\":dataset[i][:]\n",
    "            })\n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b531a8-bee2-4e15-a2ec-c06ba0521ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    " \n",
    "import argparse\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RecurrentNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers, dropout, netType):\n",
    "        super(RecurrentNet, self).__init__()\n",
    "        self.n_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if netType == 'LSTM':\n",
    "            self.rec = nn.LSTM(input_size, hidden_size, num_layers, dropout = dropout, batch_first = True)\n",
    "        if netType == 'GRU':\n",
    "            self.rec = nn.GRU(input_size, hidden_size, num_layers, dropout = dropout, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rec(x)\n",
    "        out = out[:,-1, :]\n",
    "        out = self.fc(out)\n",
    "        return(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9181bc4d-b5de-41b6-bfb5-8e6af8759f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "x_data = []\n",
    "\n",
    "\n",
    "#print(type(data))\n",
    "n_outputs = 0\n",
    "for k in classes:\n",
    "    try:\n",
    "        x_data.extend(read_hdf(\"D:/MLdata/\" + k + \".hdf5\"))\n",
    "        \n",
    "        n_outputs += 1\n",
    "    except:\n",
    "        pass\n",
    "random.shuffle(x_data)\n",
    "\n",
    "shape1 = len(x_data[0]['data'])\n",
    "\n",
    "shape2 = len(x_data[0]['data'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad72b9b-c0d5-4aad-9a8e-1ad691c3a7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526134a4-64b1-485c-85f4-9abe6f74c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop\n"
     ]
    }
   ],
   "source": [
    "y_data = []\n",
    "x_values = []\n",
    "for i in x_data:\n",
    "    y_data.append(y_col[i['name']])\n",
    "    #x_values.append(i['data'].flatten())\n",
    "    x_values.append((i['data']).flatten())\n",
    "print(y_data[300])\n",
    "#print(x_values[300][-5:-1])\n",
    "#print(x_values[350][-5:-1])\n",
    "#print(x_values[10][-5:-1])\n",
    "#print(x_values[1000][-5:-1])\n",
    "#print(len(x_values))\n",
    "#for k in range(20):\n",
    "#    for j in range(20):\n",
    "#        print(len(x_values[k][j]))\n",
    "#print(len(x_values[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacecd30-4746-4541-aecb-23b947c14ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7994\n",
      "[-37.227165 -35.425175 -53.35134  ... -64.781525 -67.23306  -64.57233 ]\n",
      "82688\n"
     ]
    }
   ],
   "source": [
    "print(len(x_values))\n",
    "print(x_values[0])\n",
    "print(len(x_values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd076d5-e8f9-4ee4-a40e-a9c6120fcc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7994\n",
      "646\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgraf\\AppData\\Local\\Temp\\ipykernel_20840\\1303450908.py:48: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  X_train, X_test, y_train, y_test = torch.tensor(X_train), torch.tensor(X_test), torch.tensor(y_train).type(torch.LongTensor), torch.tensor(y_test).type(torch.LongTensor)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "#x_col = x_data.to_numpy()\n",
    "#print(len(y_col))\n",
    "#print(len(x_col))\n",
    "#print(len(x_col[0]))\n",
    "#classes = set(y_col)\n",
    "#print(len(classes))\n",
    "\n",
    "#flatten x to normalize then unflatten\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x_values)\n",
    "#print(x_scaled[1])\n",
    "x_values = np.reshape(x_scaled.astype(np.float32), (len(x_values),shape1,shape2))\n",
    "#print(\"first element ox x\")\n",
    "#print(x_values[0])\n",
    "counter = 0\n",
    "x_transposed = []\n",
    "for i in x_values:\n",
    "    j = np.transpose(i)\n",
    "    x_transposed.append(j)\n",
    "\n",
    "print(len(x_transposed))\n",
    "\n",
    "print(len(x_transposed[0]))\n",
    "\n",
    "print(len(x_transposed[0][0]))\n",
    "y_data = label_encoder.fit_transform(np.ravel(y_data))\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "#print(\"possible values:\")\n",
    "#print(set(y_data))\n",
    "#print(y_data)\n",
    "encoder = OneHotEncoder(drop=None, sparse=False)\n",
    "#print(\"possible values:\")\n",
    "#print(set(y_data))\n",
    "# transform data\n",
    "onehot_y = encoder.fit_transform(y_data)\n",
    "#print(onehot_y)\n",
    "#print(y_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_transposed , onehot_y,  test_size=0.2)\n",
    "#print(X_train[3])\n",
    "#print(y_train[3])\n",
    "X_train, X_test, y_train, y_test = torch.tensor(X_train), torch.tensor(X_test), torch.tensor(y_train).type(torch.LongTensor), torch.tensor(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1aafbc-0fdb-4845-92e9-20bfd8dcab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(X_train))\n",
    "#print(X_train[0])\n",
    "#print(len(X_train[0]))\n",
    "#print(len(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b1bcbb-1847-4058-b852-8ab334a2aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def testAccuracy(model):\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            audio, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "           # print(\"inputs\")\n",
    "            #print(audio[0])\n",
    "            #print(len(audio))\n",
    "            #print(len(audio[0]))\n",
    "            outputs = model(audio)\n",
    "            #print(\"outputs\")\n",
    "            #print(outputs[0])\n",
    "            #print(len(outputs))\n",
    "           # print(len(outputs[0]))\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            labels = torch.max(labels, 1)[1]\n",
    "            #print(\"labels\")\n",
    "            #print(labels)\n",
    "            #print(\"predicted\")\n",
    "            #print(predicted)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, num_epochs, lr, gamma):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    accuracies = []\n",
    "    optimizer = torch.optim.AdamW(net.parameters(),lr=lr,weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (audio, labels) in enumerate(train_loader, 0):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(audio)\n",
    "        \n",
    "            # compute the loss based on model output and real labels\n",
    "            \n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            #print(loss_fn(outputs[0], torch.argmax(labels[0])))\n",
    "            \n",
    "            loss = loss_fn(outputs, torch.max(labels, 1)[1])\n",
    "            #print(loss)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            \n",
    "        accuracy = testAccuracy(model)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        if epoch % 10 == 0:\n",
    "            scheduler.step()\n",
    "            #print('epoch:', epoch+1,' test accuracy: %d %%' % (accuracy))\n",
    "            #print(loss)\n",
    "    plt.ylim([0, 100])    \n",
    "    plt.plot(list(range(1,max_epochs+1)), accuracies)\n",
    "    plt.xlabel(\"Number of epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff18ee4-fcb9-4d42-a998-a38bf6dd4fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a852cb-9290-4c14-88bf-cd2bbca061b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Type: LSTM  number of layers: 2 \n"
     ]
    }
   ],
   "source": [
    "num_input = X_train.shape[1] - 1\n",
    "\n",
    "#print(X_train[0])\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset,\n",
    "                                 batch_size=train_dataset.__len__())\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset,\n",
    "                                 batch_size=test_dataset.__len__())\n",
    "\n",
    "\n",
    "\n",
    "max_epochs = 50\n",
    "#net = RecurrentNet(input_size = 128, hidden_size = 20, num_classes = 8, num_layers = 2, dropout = 0.1, netType = 'LSTM')\n",
    "#train(net, train_loader, max_epochs, 0.03, 0.98)\n",
    "for netType in ['LSTM', 'GRU']:\n",
    "    for n_layers in [2,3]:\n",
    "        print('Net Type:', netType,' number of layers: %d ' % (n_layers))   \n",
    "        net = RecurrentNet(input_size = 128, hidden_size = 20, num_classes = 8, num_layers = n_layers, dropout = 0.1, netType = netType)\n",
    "        train(net, train_loader, max_epochs, 0.01, 0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6221b64-4b83-4e43-bdfd-873157103da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# try only using one in every 19 time frames\n",
    "X_subset = []\n",
    "X_averages = []\n",
    "X_ensemble = []\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for i in x_transposed:\n",
    "    xi_sub = []\n",
    "    xi_avg = []\n",
    "    xi_ensemble = []\n",
    "    for bingus in range(19):\n",
    "        xi_ensemble.append([])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for time_subset in range(34):\n",
    "        running_avg = np.zeros(128)\n",
    "        xi_sub.append(i[19 * time_subset])\n",
    "        for j in range(19):\n",
    "            running_avg += i[19 * time_subset + j]\n",
    "            xi_ensemble[j].append(i[19 * time_subset + j])\n",
    "        xi_avg.append(running_avg/19)\n",
    "    X_subset.append(xi_sub)\n",
    "    X_averages.append(xi_avg)\n",
    "    X_ensemble.append(xi_ensemble)\n",
    "\n",
    "#print(\"hi\")\n",
    "#print(len(X_subset))\n",
    "#print(len(X_subset[0]))\n",
    "#print(len(X_subset[0][0]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset , onehot_y,  test_size=0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = torch.tensor(X_train), torch.tensor(X_test), torch.tensor(y_train).type(torch.LongTensor), torch.tensor(y_test).type(torch.LongTensor)\n",
    "        \n",
    "num_input = X_train.shape[1] - 1\n",
    "\n",
    "#print(X_train[0])\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset,\n",
    "                                 batch_size=train_dataset.__len__())\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset,\n",
    "                                 batch_size=test_dataset.__len__())\n",
    "\n",
    "\n",
    "max_epochs = 1000\n",
    "      \n",
    "#net = RecurrentNet(input_size = 128, hidden_size = 30, num_classes = 8, num_layers = 2, dropout = 0.1, netType = 'LSTM')\n",
    "#train(net, train_loader, max_epochs, 0.01, 0.997)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b0072-834e-4e0c-b288-de4eabcc1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# try averaging X_train, X_test every 19 timesteps to reduce complexity\n",
    "print(\"averages:\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_averages, onehot_y,  test_size=0.2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = torch.tensor(X_train), torch.tensor(X_test), torch.tensor(y_train).type(torch.LongTensor), torch.tensor(y_test).type(torch.LongTensor)\n",
    "        \n",
    "num_input = X_train.shape[1] - 1\n",
    "\n",
    "#print(X_train[0])\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset,\n",
    "                                 batch_size=train_dataset.__len__())\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset,\n",
    "                                 batch_size=test_dataset.__len__())\n",
    "\n",
    "\n",
    "max_epochs = 500\n",
    "      \n",
    "net = RecurrentNet(input_size = 128, hidden_size = 30, num_classes = 8, num_layers = 2, dropout = 0.1, netType = 'LSTM')\n",
    "net = net.double()\n",
    "train(net, train_loader, max_epochs, 0.01, 0.997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892da39-3ded-4312-b052-2e95b128bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try ensemble learning \n",
    "\n",
    "max_epochs = 300\n",
    "models = []\n",
    "test_sets = []\n",
    "for k in range(6):\n",
    "    net = RecurrentNet(input_size = 128, hidden_size = 30, num_classes = 8, num_layers = 2, dropout = 0.1, netType = 'LSTM')\n",
    "    models.append(net)\n",
    "    ensemble_train = []\n",
    "    for data in X_ensemble:\n",
    "        ensemble_train.append(data[3*k])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_subset , onehot_y,  test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = torch.tensor(X_train), torch.tensor(X_test), torch.tensor(y_train).type(torch.LongTensor), torch.tensor(y_test).type(torch.LongTensor)\n",
    "        \n",
    "    num_input = X_train.shape[1] - 1\n",
    "    \n",
    "    test_sets.append((X_test, y_test))\n",
    "\n",
    "#print(X_train[0])\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader  = torch.utils.data.DataLoader(train_dataset,\n",
    "                                 batch_size=train_dataset.__len__())\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,\n",
    "                                 batch_size=test_dataset.__len__())\n",
    "    \n",
    "    train(net, train_loader, max_epochs, 0.01, 0.997)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe313d3-2147-47ad-aa93-333c2f9a0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = []\n",
    "label_list =[]\n",
    "    \n",
    "for k in range(6):\n",
    "    model = models[k]\n",
    "    X_test, y_test = test_sets[k]\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,\n",
    "                                 batch_size=test_dataset.__len__())\n",
    "    \n",
    "    \n",
    "    \n",
    "    counter = 0\n",
    "    for data in test_loader:\n",
    "        \n",
    "            \n",
    "        audio, labels = data\n",
    "           \n",
    "        outputs = model(audio)\n",
    "        votes.append(outputs)\n",
    "        if len(label_list) == 0:\n",
    "            label_list.append(labels)\n",
    "        counter += 1\n",
    "\n",
    "accuracy = 0            \n",
    "#print(votes)\n",
    "#print(sum(votes))\n",
    "#print(sum(votes).type())\n",
    "#print(label_list)\n",
    "_, predicted = torch.max(sum(votes), 1)\n",
    "    \n",
    "labels = torch.max(label_list[0],1)[1]\n",
    "accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "accuracy = (100 * accuracy / len(votes[0]))\n",
    "print(\"Ensemble learning accuracy: %d %%\" % (round(accuracy)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91706d16-600a-4354-b988-6729297f2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_averages))\n",
    "print(len(X_averages[0]))\n",
    "print(len(X_averages[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b527408-987b-4908-b39b-a9e130a0c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_ensemble))\n",
    "print(len(X_ensemble[0]))\n",
    "print(len(X_ensemble[0][0]))\n",
    "print(len(X_ensemble[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e7277-a5d0-4283-bc02-f14f1b2aeca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d607445-f306-49c8-aff6-ca2b51ccded4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
